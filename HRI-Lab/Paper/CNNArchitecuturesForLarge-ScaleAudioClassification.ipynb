{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320b64ce-24ae-4bed-a701-4d621bf28f61",
   "metadata": {},
   "source": [
    "# CNN Architectures for large-scale audio classification(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60614b2b-41c1-402f-8bdb-47752d03cee0",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd79ca5-0a7b-4f41-9be5-78f5ba0dbff0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6292e14-98bb-472c-bc55-e7a76a8f671d",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f0cd9-4b0e-4b72-8380-46cae5ac059b",
   "metadata": {},
   "source": [
    "CNNは音分類にも有用なのか試したい。\n",
    "我々は7000万のトレーニングビデオと30,871のラベルを持つYoutube-100Mというデータセットを用意した。\n",
    "音情報を用いてビデオ単位でのラベル付けを優先タスクとする。\n",
    "以下のことを調査する。\n",
    "有名なDNNアーキテクチャはビデオの音分類のタスクでどのように比較されるか。\n",
    "トレーニングセットとラベルセットの大きさを変更して、それが精度にどのような違いをもたらすか。\n",
    "今回は時間的に何も変化させていないので、RNNは用いない。\n",
    "\n",
    "視覚ベースのビデオ分類[20]をまねて、単一の分類器に、ビデオを重複の無いセグメントに分割したものを入力し、それぞれのセグメントの予測結果を平均するという方法を採る。[20]の研究者らは、時間を超えた情報を結び付けるためのより複雑なモデルの調査をしたのち、単一フレームを入力とするCNN分類器の出力を平均化したものが複雑なモデルと似た性能を示すことを発見した。\n",
    "[21]内で、AEDタスクはマルチインスタンス学習問題の1つとみなせると考えたが、マルチインスタンス学習のスケーリング問題はまだ解決できていないとも述べている。対照的に我々は、より巨大なデータセットに対して弱ラベルを用いた学習の限界について調査した。多くの個々のセグメントが情報を持たないのに対して、我々は十分な学習が行われれば、NETは有用な手掛かりに目をつける方法を学ぶことを望んでいる。我々は、どれくらいラベルが「弱い」かを定量化することはできない(つまり、どれくらいの割合のセグメントが情報を持たないか)し、大部分のクラス(例えばコンピューターハードウェア、ボーイング757、ビー玉(オーリー))に対して、関係性を決定付ける明確な方法ではない。いくつかのクラス(ビーチとか)については、背景の雰囲気はそれ自体情報を持つ。\n",
    "\n",
    "我々はデータセットのサイズによって、巨大なモデル容量のあるネットワークを調べることができ、完全に画像分類のアイディアを活用できる。複数のフレームのログメルスペクトグラムを計算することによって我々は分類器に入力する、二次元画像のようなパッチを作製する。時間軸と頻度軸の明らかに異なる意味が音特有のアーキテクチャに合わないかもしれないが、この試みは、Inception-V3やResNet-50といった最小限に変えた画像分類ネットワークを用いている。我々はトレーニングセットのサイズが性能に与える影響を評価するために、23K～70MのYoutube-100Mのサブセットで学習させ、サブセットのラベルを400~300Kの間で変えてモデルを学習させることで、一般的にラベルセットのサイズがどれくらい影響するかを調査する。ここで、性能は単一の共通するラベルセットを用いて評価する。我々は、AudioSetデータセット上で、我々のネットワークの一つからUmbeddingで学習させたモデルの性能を調べることで、AEDに我々のネットワークがどれだけ有効なのかを調査する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d99ee16-c912-4072-be9c-9d1225f60658",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc23057-844c-4882-9277-f0fbd781f8e0",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54420773-fad2-42a9-9281-0581aa05dc69",
   "metadata": {},
   "source": [
    "Youtube-100Mは、1億のYoutubeビデオから構成されており、7000万ビデオが学習用、1000万ビデオが評価用、そして残りの2000万ビデオがバリデーション用のものである。ビデオは平均4.6分で、合計540万時間(学習)にもなる。これらのビデオのそれぞれは、(knowledge graph:知識グラフから)30,871個ラベルから一つ以上の識別子でラベル付けされている。一つのラベルには平均して約5ラベルが付けられている。ラベルはそれぞれのビデオのメタデータ(タイトル、説明、コメント)や、背景、画像の内容の組み合わせに基づいて、自動的に割り当てられている。ラベルはビデオ全体に適用され、非常に包括的なもの(例えば、歌)から特定のもの(ウ(水鳥))まである。表1はラベルの例である。  \n",
    "　機械が生成したので、ラベルは100％正確ではないし、3000のラベルのうちいくつかは明らかに音響的に関係がある(トランペットなど)一方で、かなりそうではないもの(Web Pageなど)もある。動画には複数の具体的なアノテーションが行われている。例えば、トランペットとラベリングされたビデオは、なんら階層性がないのに、よく「エンターテインメント」としてもラベル付けされている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9c957-72af-4d7a-b5cb-3c47c0a673bb",
   "metadata": {},
   "source": [
    "> 表1:3万セットから得られるラベルの例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f17a15-6156-4596-a520-69f4fe099f4f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ae78d-89ba-40ad-a8da-e10df046da1b",
   "metadata": {},
   "source": [
    "## 3. Experimental framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9090d675-0055-405e-a7e5-4abca3225054",
   "metadata": {},
   "source": [
    "### 3.1 Traning  \n",
    " 音は重複なく、960[ms]の長さのフレームに分けられる。これは学習用の7000万本(524万時間)の動画からおよそ200億の例を取得できる。それぞれのフレームは動画全体のラベルを全て引き継ぐ。960[ms]のフレームは、短時間フーリエ変換(STFT)を10[ms]ごとに25[ms]の窓関数に適用して分解される。結果的に生じたスペクトログラムは、メル間隔度数のビンにまとめられ、そして数的な問題を避けるために、小さなオフセットを追加した後にそれぞれのビンの大きさは対数変換される。これは、すべての分類器に対する入力を形作る96x64のビンのログメルスペクトログラムのパッチを与える。トレーニングの間、我々は全てのパッチからランダムにサンプリングすることで、128個の入力からなるミニバッチを用意した。  \n",
    " 　全ての実験はTensorFlowを用い、そして複数のGPU上でAdam[23]最適化を用いて非同期で学習が行われた。  \n",
    "我々はgrid searchを、Learning rate, batch size、GPUの数、parameter serverに対して行った(ハイパーパラメータの最適化)。Batch Normalizationは後に全ての畳み込み層に適用された。すべてのモデルで、最終層にはソフトマックスではなくシグモイドが用いられた(それぞれの例が複数ラベルを持つため)。損失関数は交差エントロピー誤差。学習セットの大きさを考慮して、dropout, weight decay, その他の一般的な正則化技術は用いていない。700万以上の例で学習させた場合には過学習の傾向は全く見られなかった。学習中、我々は検証セットを用いて最高精度と[mAP](https://kikaben.com/mean-average-precision/)(mean Average Precision)で途中経過を監視した。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f787c3b-9425-4b83-9b7c-2607bc5da1c4",
   "metadata": {},
   "source": [
    "### 3.2 Evaluation  \n",
    "　1000万の評価ビデオから、我々はバランスのとれた3つのセット(おおよそ33の例が各クラスに含まれている)を作った。つまり、3万個のラベルに対して100万本の動画が対応し、3087(以降3000)個の最も高い頻度のラベルに対しては10万本のビデオが対応し、400個の最も高い頻度のラベルに対しては1万2000本の動画が対応する。それぞれの評価ビデオから得られた各960[ms]のフレームを分類器に渡した。そして、動画内の全てのセグメントから得られた分類器の出力スコアを平均化した。\n",
    " 評価基準に対して、我々は、AUC(等価なd-primeクラス分離としても報告されている)や、mAP(mean Average Precision)の全てのクラスに渡って、バランスの取れた平均を計算した。AUC(Area under the curve)は、ROC(受信者動作特性)曲線(Receiver Operationg Characteristic curve)の下の面積のことで、つまり誤ってNegativeであるものをPositiveであると分類した確率(偽陽性)の関数として正しく陽性だと分類した確率(正答率)のことである。そして完全な分類のAUCは1.0(感度d'=∞の場合と一致する)になり、あてずっぽう(d'=0)¹だとAUCは0.5になる。ｍAPはクラス群のAP(Average Precision)の平均のことで、APはそれぞれ個々のPositive試行を含むくらい十分に長い表に渡って、平均化された試行ランキング表におけるPositiveの割合(つまり適合率のことである。APは特定の回復リスト長を必要としない、適合率の指標として広く用いられてきたが、AUCとは違って、クラスの事前確率と直接的に相互関係を持つ。我々のクラスのほとんどが極めて低い事前確率(<10^-4)であるため、空振り率(False alarm rate)は低いとしても、我々が報告したｍAPは典型的に小さい。\n",
    " [1]d' = √2 * F^-1(AUC)　ここで、F^-1は単位ガウス分布の逆累積分布関数である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20744b5c-cad3-4c3e-8d24-c304887d8b66",
   "metadata": {},
   "source": [
    "### 3.3 Architecture  \n",
    "　我々の基準は完全結合DNNで、そしてそれは成功している画像分類器を詳細に模倣したいくつかのネットワークと比較された。我々の基準となる実験では、学習と評価を、元の3万ラベルのうち最も頻度の高い10％のラベル(つまり3000ラベル)のみを用いて行った。それぞれの実験で、我々はフレーム単位での分類精度のために、GPUの数とLearning Rateを粗く最適化した。最適なGPUの数は全体の演算能力と通信オーバーヘッドの間での妥協を表しており、それはアーキテクチャによって異なる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15558d32-73b4-418a-9281-7bbd5502cbe5",
   "metadata": {},
   "source": [
    "3.3.1 Fully Connected\n",
    " 我々の基準となるネットワークはReLU活性化、N層、各層につきMニューロンの完全結合モデルである。NとMは以下の、N = [2, 3, 4, 5, 6], M = [500, 1000, 2000, 3000, 4000]の中から探した。結果として、最も性能の良いモデルはN = 3, M = 1000, Learning rate = 3x10^-5の時で、10個のGPUと5つのパラメータサーバを用いた。このネットワークはおおよそ1120万個の重みと1120万個の乗数を持つ。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdbbb12-a219-4851-b8eb-37b2047e9b2d",
   "metadata": {},
   "source": [
    "### 3.3.2 AlexNet  \n",
    "　オリジナルのAlexNetアーキテクチャは224x224x3の入力サイズと、stride = 4の頭の11x11畳み込み層を持つ。我々の入力サイズは96x64であるため、活性化層が入力層の後の層で似るように、stride = 2 x 1として用いた。また、Local response normalization(LRN)の代わりにそれぞれの畳み込み層後にbatch normalizationを用い、1000ニューロンの最終層を3087個のニューロンに置き換えた。オリジナルのAlexNetがおおよそ6240万個の重みと11億個の乗数を持つが、我々のバージョンは3730万個の重みと7億6700万個の乗数を持つ。さらに、簡単のために、AlexNetとは違い、複数のデバイス間でフィルターを分割しない。そして、20個のGPUと10個のパラメータサーバーを用いて学習させた。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9215cfe0-de68-4ca9-a105-99ba1c5a83bb",
   "metadata": {},
   "source": [
    "### 3.3.3 VGG  \n",
    "　我々がVGG(Configuration: E)に対して行ったわずかな変更は、LRN(Local response normalization)の代わりにbatch normalizationを用いたことと、活性化関数としてsigmoidを用いた3087ニューロン最終層に対するものである。オリジナルのネットワークが1億4400万個の重みと200億の乗数を持つが、音を用いるバージョンは6200万個の重みと24億の乗数を持つ。(AlexNetに対して行ったように)始めのstrideを減らした他のバージョンも試したが、strideを修正しない方が早く学習でき、よい性能を示すことが分かった。我々の設定で、10個より多いGPUで並列処理することは、大きく役立つわけではなかったので、10個のGPUと5つのパラメータサーバで学習を行った。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c0a733-8f8f-4dc3-85ed-74b4f19458c9",
   "metadata": {},
   "source": [
    "> 表2: 3000個のラベル付けがそれぞれ為された7000万本の動画を用いて学習させた複数のDNNアーキテクチャのパフォーマンスの比較\n",
    "　最終行は他のモデルよりもLearning rateを1300万ステップ後に減少させることで、かなり長く学習させたモデルの結果を含んでいる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2049e789-262b-4389-8977-b4a5e55adcc4",
   "metadata": {},
   "source": [
    "### 3.3.4 Inception V3\n",
    " 我々はinception V3のネットワークの補助ネットワークを取り除くだけでなく、MaxPool以下であり、幹である最初の4層を取り除くことで修正した。そして活性化の変化を反映させるためにAveragePoolサイズを10x6に変更した。我々は幹を残してみたり、最初のstride = 2とMaxPoolを取り除いたり試したが、幹を取り除いたバージョンよりも性能が悪くなることが分かった。オリジナルのネットワークは2700万の重みと56億の乗数を持っており、音に対応したバージョンでは2800万の重みと47億の乗数を持つ。我々は40個のGPUと20個のパラメータサーバを用いた。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89021478-9fbd-4bbc-afa4-5a0a44c2aa04",
   "metadata": {},
   "source": [
    "### 3.3.5 ResNet-50\n",
    "　我々はResNet-50を、活性化の数が音に対応したバージョンにおいて大きく異ならないように、最初の7x7の畳み込みにおけるstride = 2を取り除くことで修正した。そしてAveragePoolサイズを、活性化の変更に対応させるため、6x4に変更した。オリジナルのネットワークが2600万個の重みと38億の乗数を持つのに対して、音に対応させたバージョンは3000万個の重みと19億の乗数を持つ。学習は20個のGPUと10個のパラメータサーバーを用いて行った。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac25de4-2b7c-4c94-a9aa-421d93bea044",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd350ad4-4ec3-4e8f-b69f-f726b8ea97f7",
   "metadata": {},
   "source": [
    "# 4. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5310b87-14ac-4c1a-b566-f5ba6e75949d",
   "metadata": {},
   "source": [
    "### 4.1 Architecture Comparison  \n",
    "全てのNNアーキテクチャに対して我々は、3000ラベルと7000万の動画で学習を行い、128個からなるミニバッチを500万回用いて学習させた後に比較を行った。他のものよりも早く学習が終わったネットワークもあったため、共通の実測時間(wall-clock time)後での比較は僅かに異なる結果になったが、アーキテクチャのパフォーマンスの相対的な順序は変わらなかった。1700万ミニバッチ(405時間分)学習後のResNetが、性能を更に上げつつあることを示す数値も記録した。我々は、学習率を1300万ミニバッチ学習後に10分の1に下げた。  \n",
    "表2は、10万の残りのビデオを用いて計算した評価結果を示している。全てのCNNは、全結合の基準値を上回った。InceptionとResNetは最高性能を達成した。そしてそれらは高いモデル容量を提供し、畳み込み層が画像、そしてこれは推測であるが、音表現の両方に対して、入力配列の異なる領域において発生するかもしれない共通構造を効率的に捉えることができる。  \n",
    "　それぞれのラベルの事前分布がどのようにその性能に影響を及ぼすのかを調べるために、図1に3万クラスの散布図を示した。ここでx軸は各ラベルの度数、y軸はResNet50のd'である。d'の分散が度数の小さなクラスにせいで増加しているのにも関わらず、d'は、ラベルの事前分布に関わらず2.0付近に位置しているように見える。これは、学習データが増加する、につれ分類器の性能が向上するという通常の結果に反しており、特に5オーダー以上にわたって一定であることが区画内で示されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b840be47-2906-462b-ad86-e60a90fb5694",
   "metadata": {},
   "source": [
    "> 図1:ResNet50の各クラスのd'-各クラスの対数事前確率の散布図。それぞれの点は、3万個のうち無作為にその20%を選んだサブセットから取り出した各クラスを表している。色はクラスのAPを反映している。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0d6873-85f2-4f7d-8e76-e9c60fc413a8",
   "metadata": {},
   "source": [
    "### 4.2 Label Set Size  \n",
    "3万ラベルのうち、400ラベルを用いて、異なるクラスのサブセットを用いた学習がどのように性能に影響を与えるのかを調査した。ひょっとしたら評価クラスであっても未知の例に対してよりよく一般化する中間表現を促すことで性能に影響を及ぼすかもしれないからだ。3つのラベルサイズ(3万、3000、400)を調べるのに加えて、通常のモデルと最終出力層の直前にある128ニューロンから成るボトルネック層を取り除いたものとを比較した。我々は、ボトルネック層を3万ラベルを用いて学習を行ったモデルの学習を早めるために導入した。ボトルネック層を取り除くと、より大きな出力層は重みの数を3000万から8000万に増加するとともに、学習時間を大幅に減らした。ボトルネックなしの3万ラベルモデルでの結果は、学習に数ヶ月要するため報告しなかった。全てのラベルセットのサイズの実験のために、ResNet50モデルを用いて、500万回128個からなるミニバッチ(約120時間)、7000万動画を用いて行った。  \n",
    "　表3はその結果を示している。ボトルネックのあるモデルを比較すると、学習の用いるラベルの数が増えるとともに性能が実際僅かに向上していることが見てとれるが、ボトルネックの無いモデルは全て性能が高くなっている。ボトルネック層は、ResNet50のAveragePool層から出てくる2048の活性化(2048ニューロン)と比較して相対的に小さいため、取り除くことで情報のかなりの減少をもたらす。これらの結果は、幅広いクラスセットで学習することは、400個程度のサブセットを公式化するのを助けるという見解に対する弱い支持をする。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece0b0c2-0660-4dc6-a7a3-eae3e11c79c9",
   "metadata": {},
   "source": [
    "> 表3:ラベルセットサイズを変化させ、400以上のラベルで評価した結果。全てのモデルは7000万動画で学習したResNet50の変化版である。ボトルネック層を用いると、128次元になる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e29f709-f169-489f-9fcb-fa16dd4618ed",
   "metadata": {},
   "source": [
    "### 4.3 Training Set Size  \n",
    " 莫大で利用可能な学習セットによって、学習セットのサイズが性能にどのように影響を与えるのか調べることができる。7000万動画そして各動画あたり平均4.6分あれば、我々は約200億個のの960[ms]の長さの学習データを用意できる。ResNet50の学習速度は20個のGPUを用いた場合毎秒11バッチであることを考慮すると、それぞれの学習データを1回見る(1エポック)ためには23週間要するだろう。しかし、もし全ての動画の長さが一定で、完全に任意抽出を行うとすると、それぞれの動画から少なくとも1フレーム見るにはたったの14時間でいいだろう。我々は、たとえ1エポック全てを流すことはできないとしても、7000万動画によって、限られた消費学習データの中に内在するより大きな動画の多様性の効力で、700万の動画全てを用いた学習に対して優位になれる、という仮説を立てた。我々は、ResNet50を1600万個の128入力からなるミニバッチ(約380時間)に対して、3000ラベルセットサイズ、7000万、700万、70万、7万そして2万3000動画で学習させた。  \n",
    "　表4にその結果を示した。7万と2万3000この動画を用いたモデルは他と比べて悪い性能を示したが、検証プロットはそれらは過学習に苦しんだようであることを示した。正規化テクニック(あるいはデータ論証)はこれら小さなトレーニングセットでの数値を高めたのかもしれない。70万、700万、7000万動画を用いたモデルは、70万モデルが僅かに劣るが、ほとんど近い性能であった。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd3e56-1284-40eb-b0ac-de5b18cabdca",
   "metadata": {},
   "source": [
    "> 表4:異なるデータ量で学習を行った結果。全ての列は同じ3000ラベルセットに含まれるラベルでタグ付けされた動画で学習を行った、同じResNet-50アーキテクチャを用いた。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9aeab8-7965-4560-91c9-667a1ac29b9a",
   "metadata": {},
   "source": [
    "### 4.4 AED with the Audio Set Dataset  \n",
    "　Audio Setは100万以上の、音響イベントラベル付けされた10秒間の抜粋のデータセットである(一方で、Youtube-100Mの全ての30Kのラベルが音響イベントに関連するものであるわけではない)。これは合計して約3000時間になる。それでもYoutube-100Mの0.05%であるが。我々はAudio Setに対してラベルを予測する二つの全結合モデルを学習させた。一つ目のモデルは、64x20ログメルスペクトログラムのパッチを用い、二つ目のモデルは我々の最も高い性能のResNetモデルの最後から二番目の畳み込み層を入力として用いている。ログメルスペクトログラムの基準値はバランスの取れたmAP=0.137、AUC=0.904(これはd'=1.846に相当する)を得た。畳み込みで学習した二つ目のモデルはmAP=0.314, AUC=0.959, d'=2.452を得た。この性能の飛躍は、ResNet分類器の出力で統合されたより巨大なYoutube-100Mの学習セットの恩恵を反映している。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c000c-d50d-4dd0-b062-bd8659fd867c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ca7804-41c0-4ea9-b7bd-88161601b88c",
   "metadata": {},
   "source": [
    "## 5. CONCLUSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca8cb9-3fa9-45fa-a31b-031db29499a0",
   "metadata": {},
   "source": [
    "　4.1節の結果で、最新の画像ネットワークは、単純全結合ネットワークや古い画像分類アークテクチャと比べて音の分類で優れた結果を出す能力があることを示した。4.2節で我々は、より巨大なラベルセットで学習することが性能を向上させることを示す結果を見た。小さなラベルセットを用いたモデルの評価においてはまあまあではあるが。4.3節では、動画の数を700万まで増加させることで最高性能を示したResNet50アーキテクチャで性能が向上することを見た。我々は、正規化が小さなデータセットで学習させたモデルと700万、7000万動画で学習させたモデルの間にある差は減らせたかもしれないことを言及しておく。4.4節ではAudio SetでResNetの畳み込み層を用いてAEDに対して学習をさせた時、基準値を大きく上回る顕著な向上を見た。  \n",
    " これらの定量化された結果に加えて、主観的に動画のセグメントでモデルの性能を調べることができた。図2に我々の最高性能の分類器が一本の動画全体に対して分類し、動画全体を通して最も大きなピーク値と、フレームごとの16分類の結果を動画の上に描画した結果を示した。動画の異なるポイントで存在する異なる音源は明確に区別されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d28e1-826b-4c1e-a3cc-e3b67d51cf0d",
   "metadata": {},
   "source": [
    ">図2:動画からの3つの抜粋がResNet-50によって分類された。ここで瞬間のモデル出力を上に描画している。動画全体で最大のピーク値を持つ16クラス分類器の出力は3万ラベルの中から表示のために選ばれている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a327d43-7571-467c-bbd1-ba9393f1cf38",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9445e4e0-b71d-458b-bbcd-f38ab4db5fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
